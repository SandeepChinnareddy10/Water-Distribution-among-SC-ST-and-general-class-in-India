{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm for Associative Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The objective is to develop rules involving regions, castes and coverage with adequate water supply\n",
    "#The data points are initially converted into transactions using discretization for the continuous variables\n",
    "#The Apriori Algorithm is used to generate frequent itemsets along with their support count\n",
    "#Rules are mined by evalutaing confidence of binary partitions of the subsets \n",
    "#Controllable parameters: \n",
    "#     min_pop : Minimum population of caste for datapoint\n",
    "#     min_pop_percentage : Minimum population percentage of caste for datapoint\n",
    "#     Discretization limits : Necessary to categorize values for discretization\n",
    "#     min_sup : Minimum Support Value\n",
    "#     min_conf : Minimum Confidence Value\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations, chain\n",
    "\n",
    "data = pd.read_csv('/Users/GJ/Desktop/DM_EndSem/final_dataset_for_2009.csv')#This dataset is the file produced after preprocessing the original data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset for Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4907\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SC Current Population</th>\n",
       "      <th>ST Current Population</th>\n",
       "      <th>GENERAL Current Population</th>\n",
       "      <th>State Name</th>\n",
       "      <th>SC percent covered</th>\n",
       "      <th>ST percent covered</th>\n",
       "      <th>GENERAL percent covered</th>\n",
       "      <th>SC Population Percentage</th>\n",
       "      <th>ST Population Percentage</th>\n",
       "      <th>GENERAL Population Percentage</th>\n",
       "      <th>Region_New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4867</td>\n",
       "      <td>19633</td>\n",
       "      <td>526</td>\n",
       "      <td>158351</td>\n",
       "      <td>bihar</td>\n",
       "      <td>91.570315</td>\n",
       "      <td>73.954373</td>\n",
       "      <td>72.429603</td>\n",
       "      <td>10.998263</td>\n",
       "      <td>0.294661</td>\n",
       "      <td>88.707075</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4868</td>\n",
       "      <td>8394</td>\n",
       "      <td>165918</td>\n",
       "      <td>34288</td>\n",
       "      <td>madhya pradesh</td>\n",
       "      <td>68.763402</td>\n",
       "      <td>56.876891</td>\n",
       "      <td>73.792580</td>\n",
       "      <td>4.023969</td>\n",
       "      <td>79.538830</td>\n",
       "      <td>16.437200</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4869</td>\n",
       "      <td>0</td>\n",
       "      <td>12776</td>\n",
       "      <td>329</td>\n",
       "      <td>arunachal pradesh</td>\n",
       "      <td>84.348722</td>\n",
       "      <td>37.343456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.489508</td>\n",
       "      <td>2.510492</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>16900</td>\n",
       "      <td>536</td>\n",
       "      <td>arunachal pradesh</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>32.881657</td>\n",
       "      <td>27.611940</td>\n",
       "      <td>0.137457</td>\n",
       "      <td>96.792669</td>\n",
       "      <td>3.069874</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4871</td>\n",
       "      <td>0</td>\n",
       "      <td>12256</td>\n",
       "      <td>374</td>\n",
       "      <td>nagaland</td>\n",
       "      <td>84.348722</td>\n",
       "      <td>66.465405</td>\n",
       "      <td>99.465241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.038797</td>\n",
       "      <td>2.961203</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SC Current Population  ST Current Population  \\\n",
       "4867                  19633                    526   \n",
       "4868                   8394                 165918   \n",
       "4869                      0                  12776   \n",
       "4870                     24                  16900   \n",
       "4871                      0                  12256   \n",
       "\n",
       "      GENERAL Current Population         State Name  SC percent covered  \\\n",
       "4867                      158351              bihar           91.570315   \n",
       "4868                       34288     madhya pradesh           68.763402   \n",
       "4869                         329  arunachal pradesh           84.348722   \n",
       "4870                         536  arunachal pradesh           37.500000   \n",
       "4871                         374           nagaland           84.348722   \n",
       "\n",
       "      ST percent covered  GENERAL percent covered  SC Population Percentage  \\\n",
       "4867           73.954373                72.429603                 10.998263   \n",
       "4868           56.876891                73.792580                  4.023969   \n",
       "4869           37.343456                 0.000000                  0.000000   \n",
       "4870           32.881657                27.611940                  0.137457   \n",
       "4871           66.465405                99.465241                  0.000000   \n",
       "\n",
       "      ST Population Percentage  GENERAL Population Percentage Region_New  \n",
       "4867                  0.294661                      88.707075          C  \n",
       "4868                 79.538830                      16.437200          C  \n",
       "4869                 97.489508                       2.510492          E  \n",
       "4870                 96.792669                       3.069874          E  \n",
       "4871                 97.038797                       2.961203          E  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "#Allocating region to each state in order to get better readability while analysing the obtained rules\n",
    "dictionary = {'andhra pradesh': 'S','arunachal pradesh': 'E','assam': 'E','bihar': 'C','chandigarh': 'N',\n",
    "  'chhattisgarh': 'C','dadra & nagar haveli': 'W','daman & diu':'W','goa': 'W','national capital territory of delhi': 'N',\n",
    "  'gujarat': 'W','haryana': 'N','himachal pradesh': 'N','jammu and kashmir': 'N','jharkhand': 'E','karnataka': 'S',\n",
    "  'kerala': 'S','ladakh': 'N','lakshadweep': 'S','madhya pradesh': 'C','maharashtra': 'S','manipur': 'E','meghalaya': 'E',\n",
    "  'mizoram': 'E','nagaland': 'E','orissa': 'E','punjab': 'N','puducherry':'S','rajasthan': 'W','sikkim': 'E',\n",
    "  'tamil nadu': 'S','telangana': 'S','tripura': 'E','uttar pradesh': 'N','uttarakhand': 'N','west bengal': 'W'}\n",
    "\n",
    "df['Region_New'] = df['State Name'].map(dictionary) #Mapping to region name based on state\n",
    "df = df.drop(columns=['District Name','Block Name','Region','State Name']) #Dropping unnecessary attributes\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe() #To estimate minimum population and population percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion of Dataset into Transaction Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', 'ST_CH', 'GN_CL']\n",
      "['S', 'SC_CH', 'ST_CH', 'GN_CH']\n",
      "['W', 'SC_CH', 'ST_CH', 'GN_CH']\n",
      "['N', 'SC_CH', 'GN_CH']\n",
      "['W', 'SC_CH', 'ST_CH', 'GN_CH']\n",
      " \n",
      "['E', 'ST_CM', 'GN_CH']\n",
      "['E', 'ST_CL', 'GN_CL']\n",
      "['E', 'ST_CL']\n",
      "['C', 'SC_CM', 'ST_CM', 'GN_CM']\n",
      "['C', 'SC_CH', 'ST_CM', 'GN_CM']\n"
     ]
    }
   ],
   "source": [
    "#The dataset set is converted to a transaction dataset in order to procede with the Apriori Algorithm\n",
    "Transactions = []#This list will contain the set of all transactions\n",
    "i = 0 \n",
    "min_pop = 100 #The minimum population required for caste to be considered in order to ignore small sample sizes\n",
    "min_pop_percetage = 0 #The minimum population percentage required for caste to be considered in order to ignore \n",
    "                       #highly disproportionate cases.\n",
    "df_size = len(df.index)# Size of Dataset\n",
    "while i<df_size:\n",
    "    T = []\n",
    "    T.append(df.loc[i,'Region_New']) # The first element of each transaction is the region name\n",
    "    c11 = df.loc[i,'SC Current Population']#Values of population, population percentage, covered population percentage\n",
    "    c21 = df.loc[i,'ST Current Population']#are extracted for the current element for each caste\n",
    "    c31 = df.loc[i,'GENERAL Current Population']\n",
    "    c12 = df.loc[i,'SC Population Percentage']\n",
    "    c22 = df.loc[i,'ST Population Percentage']\n",
    "    c32 = df.loc[i,'GENERAL Population Percentage']\n",
    "    c13 = df.loc[i,'SC percent covered'] \n",
    "    c23 = df.loc[i,'ST percent covered'] \n",
    "    c33 = df.loc[i,'GENERAL percent covered']\n",
    "\n",
    "    D1 = 80 #These are the boundaries for classifying a point into high,medium or low water coverage\n",
    "    D2 = 40\n",
    "    if c11>min_pop and c12>min_pop_percetage:\n",
    "        if c13>D1:\n",
    "            T.append('SC_CH')#This implies the datapoint has high population of SC covered with adequate water\n",
    "        else: \n",
    "            if c13>D2:\n",
    "                T.append('SC_CM')#This implies the datapoint has medium population of SC covered with adequate water\n",
    "            else:\n",
    "                if c13!=0:\n",
    "                    T.append('SC_CL')#This implies the datapoint has low population of SC covered with adequate water  \n",
    "    if c21>min_pop and c22>min_pop_percetage:\n",
    "        if c23>D1:\n",
    "            T.append('ST_CH')#This implies the datapoint has high population of ST covered with adequate water\n",
    "        else: \n",
    "            if c23>D2:\n",
    "                T.append('ST_CM')#This implies the datapoint has medium population of ST covered with adequate water\n",
    "            else:\n",
    "                if c23!=0:\n",
    "                    T.append('ST_CL')#This implies the datapoint has low population of ST covered with adequate water\n",
    "    if c31>min_pop and c32>min_pop_percetage:\n",
    "        if c33>D1:\n",
    "            T.append('GN_CH')#This implies the datapoint has high population of GENERAL covered with adequate water\n",
    "        else: \n",
    "            if c33>D2:\n",
    "                T.append('GN_CM')#This implies the datapoint has medium population of GENERAL covered with adequate water\n",
    "            else:\n",
    "                if c33!=0:\n",
    "                    T.append('GN_CL')#This implies the datapoint has low population of GENERAL covered with adequate water \n",
    "    i = i+1            \n",
    "    Transactions.append(T)\n",
    "#Printing the first and last five elements of transaction dataset\n",
    "i = 0\n",
    "while i<5:\n",
    "    print(Transactions[i])\n",
    "    i = i+1\n",
    "i = 1\n",
    "print(\" \")\n",
    "while i<=5:\n",
    "    print(Transactions[df_size-i])\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Itemset Generation from Transaction Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets of size -  1 , number of elements -  14 \n",
      " [['N'], ['S'], ['E'], ['W'], ['C'], ['SC_CH'], ['SC_CM'], ['SC_CL'], ['ST_CH'], ['ST_CM'], ['ST_CL'], ['GN_CH'], ['GN_CM'], ['GN_CL']] \n",
      "\n",
      "Corredsponding Support: \n",
      " [731, 2093, 779, 455, 814, 3161, 1229, 187, 2202, 1224, 212, 2999, 1524, 232]\n",
      " \n",
      "Frequent Itemsets of size -  2 , number of elements -  38 \n",
      " [['N', 'SC_CH'], ['SC_CM', 'N'], ['GN_CH', 'N'], ['GN_CM', 'N'], ['SC_CH', 'S'], ['SC_CM', 'S'], ['ST_CH', 'S'], ['ST_CM', 'S'], ['GN_CH', 'S'], ['GN_CM', 'S'], ['SC_CH', 'E'], ['SC_CM', 'E'], ['ST_CH', 'E'], ['ST_CM', 'E'], ['GN_CH', 'E'], ['GN_CM', 'E'], ['W', 'SC_CH'], ['ST_CH', 'W'], ['GN_CH', 'W'], ['C', 'SC_CH'], ['C', 'SC_CM'], ['ST_CH', 'C'], ['ST_CM', 'C'], ['GN_CH', 'C'], ['GN_CM', 'C'], ['ST_CH', 'SC_CH'], ['ST_CM', 'SC_CH'], ['GN_CH', 'SC_CH'], ['GN_CM', 'SC_CH'], ['ST_CH', 'SC_CM'], ['ST_CM', 'SC_CM'], ['GN_CH', 'SC_CM'], ['GN_CM', 'SC_CM'], ['SC_CL', 'GN_CL'], ['GN_CH', 'ST_CH'], ['ST_CH', 'GN_CM'], ['ST_CM', 'GN_CH'], ['ST_CM', 'GN_CM']] \n",
      "\n",
      "Corredsponding Support: \n",
      " [522, 108, 538, 139, 1693, 349, 1393, 368, 1684, 364, 160, 346, 196, 462, 168, 453, 345, 308, 341, 441, 347, 245, 255, 268, 487, 1965, 233, 2810, 336, 168, 793, 119, 1043, 114, 1915, 247, 202, 909]\n",
      " \n",
      "Frequent Itemsets of size -  3 , number of elements -  28 \n",
      " [['GN_CH', 'N', 'SC_CH'], ['SC_CH', 'ST_CH', 'S'], ['GN_CH', 'SC_CH', 'S'], ['ST_CM', 'SC_CM', 'S'], ['GN_CM', 'SC_CM', 'S'], ['GN_CH', 'ST_CH', 'S'], ['ST_CM', 'GN_CM', 'S'], ['SC_CH', 'ST_CH', 'E'], ['ST_CM', 'SC_CM', 'E'], ['GN_CM', 'SC_CM', 'E'], ['GN_CH', 'ST_CH', 'E'], ['ST_CM', 'GN_CM', 'E'], ['ST_CH', 'W', 'SC_CH'], ['GN_CH', 'W', 'SC_CH'], ['GN_CH', 'ST_CH', 'W'], ['ST_CH', 'C', 'SC_CH'], ['GN_CH', 'C', 'SC_CH'], ['GN_CM', 'C', 'SC_CH'], ['ST_CM', 'C', 'SC_CM'], ['GN_CM', 'C', 'SC_CM'], ['GN_CH', 'ST_CH', 'C'], ['ST_CM', 'GN_CM', 'C'], ['GN_CH', 'ST_CH', 'SC_CH'], ['ST_CH', 'GN_CM', 'SC_CH'], ['ST_CM', 'GN_CH', 'SC_CH'], ['ST_CM', 'GN_CM', 'SC_CH'], ['ST_CH', 'GN_CM', 'SC_CM'], ['ST_CM', 'GN_CM', 'SC_CM']] \n",
      "\n",
      "Corredsponding Support: \n",
      " [517, 1325, 1640, 265, 303, 1315, 266, 104, 260, 311, 103, 327, 297, 334, 292, 195, 224, 203, 176, 273, 160, 211, 1839, 121, 130, 102, 113, 726]\n",
      " \n",
      "Frequent Itemsets of size -  4 , number of elements -  6 \n",
      " [['GN_CH', 'SC_CH', 'ST_CH', 'S'], ['ST_CM', 'GN_CM', 'SC_CM', 'S'], ['ST_CM', 'GN_CM', 'SC_CM', 'E'], ['GN_CH', 'ST_CH', 'W', 'SC_CH'], ['GN_CH', 'ST_CH', 'C', 'SC_CH'], ['ST_CM', 'GN_CM', 'C', 'SC_CM']] \n",
      "\n",
      "Corredsponding Support: \n",
      " [1292, 244, 241, 288, 141, 159]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# # Frequent Itemset Generation\n",
    "\n",
    "def Support_Counting(T,C):\n",
    "    Supp = []\n",
    "    for x in C:\n",
    "        i = 0\n",
    "        s = 0\n",
    "        while i<df_size:\n",
    "            if (set(x).issubset(set(T[i])))==True:\n",
    "                s = s+1\n",
    "            i = i+1\n",
    "        Supp.append(s)  \n",
    "    return Supp\n",
    "    \n",
    "def Candidate_Generation(List,k):\n",
    "    C = ['N','S','E','W','C','SC_CH','SC_CM','SC_CL','ST_CH','ST_CM','ST_CL','GN_CH','GN_CM','GN_CL']\n",
    "    if k == 1:\n",
    "        C = [['N'],['S'],['E'],['W'],['C'],['SC_CH'],['SC_CM'],['SC_CL'],['ST_CH'],['ST_CM'],['ST_CL'],['GN_CH'],\n",
    "             ['GN_CM'],['GN_CL']]\n",
    "        return C\n",
    "    else:\n",
    "        L = list(map(set, itertools.combinations(C,k)))\n",
    "        return L\n",
    "\n",
    "def Support_Pruning(C,S):\n",
    "    min_sup = 100\n",
    "    I = []\n",
    "    F = []\n",
    "    FS = []\n",
    "    for x in C:\n",
    "        i = C.index(x)\n",
    "        if S[i]<min_sup:\n",
    "            I.append(list(x))\n",
    "        else:\n",
    "            F.append(list(x))\n",
    "            FS.append(S[i])\n",
    "    return F,FS,I\n",
    "\n",
    "def Subset_Pruning(C,I):\n",
    "    if I!=[]:\n",
    "        Ind = I\n",
    "        for x in I:\n",
    "            for y in C:\n",
    "                if (set(x).issubset(y))==True:\n",
    "                    Ind.pop(Ind.index(x))\n",
    "                    break\n",
    "    return C\n",
    "\n",
    "k = 1\n",
    "Cand = [] #Corresponds to all candidates generated i.e. Ci\n",
    "Infreq_Cand = [] #Correspods to candidates which were pruned \n",
    "List = [] #Corresponds to set of frequent candidates i.e Li\n",
    "Support = [] #Corresponds to a list containing support values reflecting all elemnts in List\n",
    "\n",
    "while k<=4: #Candidate generation is required only till size 4 because the maximum size of any transaction is 4\n",
    "    C = Candidate_Generation(List,k) # This function generates all possible candidates of size k \n",
    "    if k!=1:\n",
    "        C = Subset_Pruning(C,Infreq_Cand) #This function prunes the generated candidates if any subset is infrequent\n",
    "    Cand.append(C)\n",
    "    S = Support_Counting(Transactions,C) #This function calculates the support for the remaining candidates\n",
    "    L,S,I = Support_Pruning(C,S) # This function prunes the canidadtes based on support count\n",
    "    List.append(L) #The remaining candidates are added to the frequent itemset list\n",
    "    Support.append(S) #The support corresponding to each candidate is added to this list in the same position as the candidate\n",
    "    if I!=[]:\n",
    "        for x in I:\n",
    "            Infreq_Cand.append(x) # Infrequent itemsets are collected in this list which are used in \"subset_pruning\" function\n",
    "    k = k+1\n",
    "i = 0\n",
    "while i<4:\n",
    "    print(\"Frequent Itemsets of size - \",i+1,\", number of elements - \",len(List[i]),\"\\n\",List[i],\"\\n\")\n",
    "    print(\"Corredsponding Support: \\n\",Support[i])\n",
    "    print(\" \")\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining Association Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GN_CH', 'N'] -> ['SC_CH'] ;Confidence= 0.9609665427509294\n",
      "['N', 'SC_CH'] -> ['GN_CH'] ;Confidence= 0.9904214559386973\n",
      "['ST_CH', 'S'] -> ['SC_CH'] ;Confidence= 0.9511844938980617\n",
      "['GN_CH', 'S'] -> ['SC_CH'] ;Confidence= 0.9738717339667459\n",
      "['SC_CH', 'S'] -> ['GN_CH'] ;Confidence= 0.9686946249261665\n",
      "['ST_CH', 'W'] -> ['SC_CH'] ;Confidence= 0.9642857142857143\n",
      "['GN_CH', 'W'] -> ['SC_CH'] ;Confidence= 0.9794721407624634\n",
      "['W', 'SC_CH'] -> ['GN_CH'] ;Confidence= 0.9681159420289855\n",
      "['GN_CH', 'ST_CH'] -> ['SC_CH'] ;Confidence= 0.960313315926893\n",
      "['GN_CH', 'ST_CH', 'S'] -> ['SC_CH'] ;Confidence= 0.9825095057034221\n",
      "['SC_CH', 'ST_CH', 'S'] -> ['GN_CH'] ;Confidence= 0.9750943396226415\n",
      "['GN_CH', 'ST_CH', 'W'] -> ['SC_CH'] ;Confidence= 0.9863013698630136\n",
      "['ST_CH', 'W', 'SC_CH'] -> ['GN_CH'] ;Confidence= 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "import copy\n",
    "\n",
    "def Generate_Subsets(S):\n",
    "    s = list(S)\n",
    "    A = chain.from_iterable(combinations(s, r) for r in range(1, len(s)))  \n",
    "    A = [list(i) for i in A]\n",
    "    return A\n",
    "\n",
    "i = 2\n",
    "CR1 = [] #list which will contain LHS of mined rules\n",
    "CR2 = [] #list which will contain RHS of mined rules\n",
    "CVal = [] #list which will contain confidence value of mined rules\n",
    "min_conf = 0.95\n",
    "\n",
    "while i<=4: #Rule generation is done iteratively for itemsets of different sizes\n",
    "    L = List[i-1] #List of frequent itemsets of size (i-1)\n",
    "    L1 = copy.deepcopy(L) #Used in order to prevent the altering of original list\n",
    "    S = Support[i-1] #Support of frequent itemsets of size(i-1)\n",
    "    while L1!=[]:\n",
    "        L2 = L1[0] \n",
    "        L3 = Generate_Subsets(L2) #Function generates all possible subsets of L2 of size 1-(n-1) where n = len(L2)\n",
    "        S1 = S[L.index(L2)] #Support value corresponding to L2\n",
    "        for A in L3: #for ever subset\n",
    "            G = List[len(A)-1]\n",
    "            if G.count(A)==1:\n",
    "                n = len(A)\n",
    "                Stemp = Support[n-1]\n",
    "                pos = List[n-1].index(A)\n",
    "                S2 = Stemp[pos] #calculates support value of subset\n",
    "                if (S1/S2)>min_conf: #calculates confidence by S1/S2\n",
    "                    B = list(set(L2)-set(A)) #the complementary subset is appended to CR2\n",
    "                    CR1.append(A)\n",
    "                    CR2.append(B)\n",
    "                    CVal.append(S1/S2)\n",
    "        L1.pop(0)\n",
    "    i=i+1\n",
    "i = 0\n",
    "while i <len(CR1):\n",
    "    print(CR1[i],\"->\",CR2[i],\";Confidence=\",CVal[i])\n",
    "    i = i+1\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
